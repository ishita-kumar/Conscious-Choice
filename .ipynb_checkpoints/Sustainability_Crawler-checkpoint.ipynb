{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from random import random\n",
    "from selenium.common import exceptions\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from msedge.selenium_tools import Edge, EdgeOptions\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_webdriver() :\n",
    "    driver=webdriver.Chrome(\"C://Users//shaha//Downloads//chromedriver_win32//chromedriver.exe\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(search_term, page):\n",
    "    base_template = 'https://www.amazon.com/s?k={}&ref=nb_sb_noss_1'\n",
    "    search_term = search_term.replace(' ', '+')\n",
    "    stem = base_template.format(search_term)\n",
    "    url_template = stem + '&page={}'\n",
    "    if page == 1:\n",
    "        print(stem)\n",
    "        return stem\n",
    "    \n",
    "    else:\n",
    "        print(url_template.format(page))\n",
    "        return url_template.format(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Product Title\n",
    "def get_title(driver):\n",
    "     \n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = driver.find_element_by_xpath(\"//span[@id='productTitle']\")\n",
    " \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    " \n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    " \n",
    " \n",
    "    except Exception:\n",
    "        title_string = \"Unknown\"   \n",
    " \n",
    "    return title_string\n",
    " \n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    " \n",
    "    try:\n",
    "        #xpathprice='//span[@id=\"price_inside_buybox\"]'\n",
    "#       price=driver.find_element_by_xpath(xpathprice)\n",
    "#       print(price.text)\n",
    "        #print(\"inside\")\n",
    "        price = soup.find_element_by_xpath(\"//span[@id='priceblock_ourprice']\").text\n",
    "        #print(\"Inside\")\n",
    "        #print(price)\n",
    " \n",
    "    except Exception:\n",
    " \n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find_element_by_xpath(\"//span[@id='priceblock_saleprice']\").text\n",
    " \n",
    "        except:     \n",
    "            price = \"\"  \n",
    " \n",
    "    return price\n",
    " \n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    " \n",
    "    try:\n",
    "        rating = soup.find_element_by_xpath(\"//span[@data-hook='rating-out-of-text']\").text\n",
    "        #print(rating)\n",
    "         \n",
    "    except Exception:\n",
    "         \n",
    "        try:\n",
    "            rating = soup.find_element_by_xpath(\"//span[@data-hook='rating-out-of-text']\").text\n",
    "        except:\n",
    "            rating = \"\" \n",
    " \n",
    "    return rating\n",
    " \n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\").text.strip()\n",
    "         \n",
    "    except Exception:\n",
    "        review_count = \"\"   \n",
    " \n",
    "    return review_count\n",
    " \n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find_element_by_xpath(\"//div[@id='availability']\")\n",
    "        available = available.find_element_by_tag_name(\"span\").text.strip()\n",
    " \n",
    "    except Exception:\n",
    "        available = \"Not Available\"\n",
    " \n",
    "    return available   \n",
    "\n",
    "def get_productdetails(soup):\n",
    "    try:\n",
    "\n",
    "\n",
    "        no_rows=len(driver.find_elements_by_xpath(\"//table[@class='a-normal a-spacing-micro']/tbody/tr\"))\n",
    "        print(no_rows)\n",
    "        no_cols=len(driver.find_elements_by_xpath(\"//table[@class='a-normal a-spacing-micro']/tbody/tr[1]/td\"))\n",
    "        print(no_cols)\n",
    "        \n",
    "        data=[]\n",
    "        for i in range(1,no_rows+1):\n",
    "            ro=[]\n",
    "            for j in range(1,no_cols+1):\n",
    "                print(driver.find_element_by_xpath('//table[@class=\"a-normal a-spacing-micro\"]/tbody/tr['+str(i)+']/td['+str(j)+']').text)\n",
    "                ro.append(driver.find_element_by_xpath('//table[@class=\"a-normal a-spacing-micro\"]/tbody/tr['+str(i)+']/td['+str(j)+']').text)\n",
    "            data.append(ro)\n",
    "        print(data)\n",
    " \n",
    "        \n",
    "    except:\n",
    "        data=\"\"\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_relatedproducts(soup):\n",
    "                count=0\n",
    "                related_products=[]\n",
    "                while count<=2:\n",
    "                    print(\"Inside while\")\n",
    "\n",
    "                    #time.sleep(3)\n",
    "                    try:\n",
    "\n",
    "                        print(\"In here\")\n",
    "                        #WebDriverWait(driver, 10).until(expected_conditions.element_to_be_clickable((By.XPATH, '//a[@class=\"a-button a-button-image a-carousel-button a-carousel-goto-nextpage\"]')))\n",
    "                        WebDriverWait(soup, 20).until(expected_conditions.visibility_of_element_located((By.XPATH, '//div[@class=\"a-carousel-col a-carousel-right\"]')))\n",
    "                        print(\"Next line\")\n",
    "                        nextpage=soup.find_element_by_xpath('//a[@class=\"a-button a-button-image a-carousel-button a-carousel-goto-nextpage\"]').get_attribute('href')\n",
    "                        soup.find_element_by_xpath('//a[@class=\"a-button a-button-image a-carousel-button a-carousel-goto-nextpage\"]').click()\n",
    "                        list=soup.find_elements_by_xpath('//div[@class=\"a-carousel-viewport\"]')\n",
    "                        print(list)\n",
    "                       \n",
    "                        for card in range(len(list)):\n",
    "                            related=soup.find_element_by_xpath('//li[@class=\"a-carousel-card\"]['+str(card+1)+']').text\n",
    "                            related_products.append(related)\n",
    "                            print(related)\n",
    "                        count+=1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        #break;\n",
    "                        print(\"Exception\",e)\n",
    "                        count+=1\n",
    "                        #condition=False\n",
    "                        print(\"In except\")\n",
    "                return related_products\n",
    "\n",
    "                print(\"After click()\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "driver = create_webdriver()\n",
    "\n",
    "for page in range(1, 2):  # max of 20 pages\n",
    "            # load the next page\n",
    "            search_url = generate_url('t-shirt', page)\n",
    "            print(search_url)\n",
    "            driver.get(search_url)\n",
    "            driver.set_page_load_timeout(10)\n",
    "            print('TIMEOUT while waiting for page to load')\n",
    "\n",
    "           \n",
    "            links=driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "            link_list=[]\n",
    "            for link in links:\n",
    "                link_list.append(link.get_attribute(\"href\"))\n",
    "                #print(link_list)\n",
    "            \n",
    "            for link in link_list:\n",
    "                driver.get(link)\n",
    "\n",
    "                # Function calls to display all necessary product information\n",
    "                print(\"Product Title =\", get_title(driver))\n",
    "                print(\"Product Price =\", get_price(driver))\n",
    "                print(\"Product Rating =\", get_rating(driver))\n",
    "                print(\"Number of Product Reviews =\", get_review_count(driver))\n",
    "                print(\"Availability =\", get_availability(driver))\n",
    "                print(\"Product Details =\", get_productdetails(driver))\n",
    "                print()\n",
    "                print()\n",
    "                \n",
    "                print(\"Related Products:\",get_relatedproducts(driver))\n",
    "                \n",
    "                title=get_title(driver)\n",
    "                price=get_price(driver)\n",
    "                rating=get_rating(driver)\n",
    "                review_count=get_review_count(driver)\n",
    "                availability=get_availability(driver)\n",
    "                product_details=get_productdetails(driver)\n",
    "                other_product_details=get_other_details(driver)\n",
    "                related_product_details=get_relatedproducts(driver)\n",
    "                individual_review_count=get_individual_rating_counts(driver)\n",
    "                img_url=get_product_img(driver)\n",
    "                reviews_basedonfeature=get_reviews_based_onfeatures(driver)\n",
    "                print(reviews_basedonfeature)\n",
    "                review_counts=get_review_comments(driver)\n",
    "                \n",
    "                \n",
    "                final_data=[]\n",
    "                data_dict={}\n",
    "                data_dict[\"Title\"]=title\n",
    "                data_dict[\"Price\"]=price\n",
    "                data_dict[\"Rating\"]=rating\n",
    "                data_dict[\"Review_Count\"]=review_count\n",
    "                data_dict[\"Availability\"]=availability\n",
    "                data_dict[\"Details\"]=product_details\n",
    "                data_dict[\"Other Product Details\"]=other_product_details\n",
    "                data_dict[\"Related Product Details\"]=related_product_details\n",
    "                data_dict[\"Individual Rating Count\"]=individual_review_count\n",
    "                data_dict[\"Product IMG Link\"]=img_url\n",
    "                data_dict[\"Feature Based Review\"]=reviews_basedonfeature\n",
    "                data_dict[\"Review Comments\"]=review_counts\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                final_data.append(data_dict)\n",
    "                f=open(\"output.json\",\"a+\")\n",
    "                f.write(json.dumps(final_data,indent=2))\n",
    "                f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
