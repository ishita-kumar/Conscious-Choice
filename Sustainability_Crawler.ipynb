{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from random import random\n",
    "from selenium.common import exceptions\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from msedge.selenium_tools import Edge, EdgeOptions\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_webdriver() :\n",
    "    driver=webdriver.Chrome(\"C://Users//shaha//Downloads//chromedriver_win32//chromedriver.exe\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(search_term, page):\n",
    "    base_template = 'https://www.amazon.com/s?k={}&ref=nb_sb_noss_1'\n",
    "    search_term = search_term.replace(' ', '+')\n",
    "    stem = base_template.format(search_term)\n",
    "    url_template = stem + '&page={}'\n",
    "    if page == 1:\n",
    "        print(stem)\n",
    "        return stem\n",
    "    \n",
    "    else:\n",
    "        print(url_template.format(page))\n",
    "        return url_template.format(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Product Title\n",
    "def get_title(driver):\n",
    "     \n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = driver.find_element_by_xpath(\"//span[@id='productTitle']\")\n",
    " \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    " \n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    " \n",
    " \n",
    "    except Exception:\n",
    "        title_string = \"Unknown\"   \n",
    " \n",
    "    return title_string\n",
    " \n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    " \n",
    "    try:\n",
    "        #xpathprice='//span[@id=\"price_inside_buybox\"]'\n",
    "#       price=driver.find_element_by_xpath(xpathprice)\n",
    "#       print(price.text)\n",
    "        #print(\"inside\")\n",
    "        price = soup.find_element_by_xpath(\"//span[@id='priceblock_ourprice']\").text\n",
    "        #print(\"Inside\")\n",
    "        #print(price)\n",
    " \n",
    "    except Exception:\n",
    " \n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find_element_by_xpath(\"//span[@id='priceblock_saleprice']\").text\n",
    " \n",
    "        except:     \n",
    "            price = \"\"  \n",
    " \n",
    "    return price\n",
    " \n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    " \n",
    "    try:\n",
    "        rating = soup.find_element_by_xpath(\"//span[@data-hook='rating-out-of-text']\").text\n",
    "        #print(rating)\n",
    "         \n",
    "    except Exception:\n",
    "         \n",
    "        try:\n",
    "            rating = soup.find_element_by_xpath(\"//span[@data-hook='rating-out-of-text']\").text\n",
    "        except:\n",
    "            rating = \"\" \n",
    " \n",
    "    return rating\n",
    " \n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\").text.strip()\n",
    "         \n",
    "    except Exception:\n",
    "        review_count = \"\"   \n",
    " \n",
    "    return review_count\n",
    " \n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find_element_by_xpath(\"//div[@id='availability']\")\n",
    "        available = available.find_element_by_tag_name(\"span\").text.strip()\n",
    " \n",
    "    except Exception:\n",
    "        available = \"Not Available\"\n",
    " \n",
    "    return available  \n",
    "\n",
    "\n",
    "def get_product_img(soup):\n",
    "    try:\n",
    "        img=soup.find_element_by_xpath(\"//div[@id='imageBlock_feature_div']\")\n",
    "        img1=soup.find_element_by_xpath(\"//*[@id='landingImage']\").get_attribute(\"src\")\n",
    "        #print(img1.get_attribute(\"src\"))\n",
    "    except:\n",
    "        img1=\"No Image Link\"\n",
    "    return img1\n",
    "\n",
    "\n",
    "def get_individual_rating_counts(driver):\n",
    "    try:\n",
    "        XPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "        total_ratings = driver.find_elements_by_xpath(XPATH_AGGREGATE_RATING)\n",
    "        #print(total_ratings)\n",
    "        ratings_dict={}\n",
    "        ratings_list=[]\n",
    "        for ratings in total_ratings:\n",
    "            extracted_rating = ratings.find_elements_by_xpath('.//td//a')\n",
    "            if extracted_rating:\n",
    "                rating_key = extracted_rating[0].text\n",
    "                raw_raing_value = extracted_rating[2]\n",
    "                rating_value = raw_raing_value.text\n",
    "                if rating_key:\n",
    "                    ratings_dict.update({rating_key: rating_value})\n",
    "                print(ratings_dict)\n",
    "        ratings_list.append(ratings_dict)\n",
    "                \n",
    "    except:\n",
    "        ratings_list=\"No Reviews\"\n",
    "    return ratings_list\n",
    "        \n",
    "def get_reviews_based_onfeatures(driver):\n",
    "    try:\n",
    "        feature_review=driver.find_elements_by_xpath(\".//div[@data-hook='cr-summarization-attributes-list']\")\n",
    "        print(feature_review)\n",
    "        feature=[]\n",
    "        feature1=[]\n",
    "        for product in feature_review:\n",
    "            print(\"Inside for\")\n",
    "            ind=product.find_elements_by_xpath(\"//div[@class='a-fixed-right-grid-inner a-grid-vertical-align a-grid-center']//div[@class='a-fixed-right-grid-col a-col-left']//span\")\n",
    "            print(ind)\n",
    "\n",
    "            ind3=product.find_elements_by_xpath(\"//div[@class='a-fixed-right-grid-inner a-grid-vertical-align a-grid-center']//div[@class='a-text-right a-fixed-right-grid-col a-col-right']//span[@class='a-size-base a-color-tertiary']\")\n",
    "            print(ind3)\n",
    "\n",
    "            for i in ind:\n",
    "                print(i.get_attribute(\"innerHTML\"))\n",
    "                feature.append(i.get_attribute(\"innerHTML\"))\n",
    "            for j in ind3:\n",
    "                print(\"Here in :\",j.get_attribute(\"innerHTML\"))\n",
    "                feature1.append(j.get_attribute(\"innerHTML\"))\n",
    "\n",
    "\n",
    "        res1 = {} \n",
    "        for v in feature: \n",
    "            for j in feature1: \n",
    "                    res1[v] = j \n",
    "                    feature1.remove(j) \n",
    "                    break  \n",
    "\n",
    "        print (\"Resultant dictionary is : \" +  str(res1)) \n",
    "\n",
    "       \n",
    "    except:\n",
    "        res1=\"No feature based reviews\"\n",
    "    return res1 \n",
    "\n",
    "\n",
    "def get_productdetails(soup):\n",
    "    try:\n",
    "\n",
    "\n",
    "        no_rows=len(driver.find_elements_by_xpath(\"//table[@class='a-normal a-spacing-micro']/tbody/tr\"))\n",
    "        print(no_rows)\n",
    "        no_cols=len(driver.find_elements_by_xpath(\"//table[@class='a-normal a-spacing-micro']/tbody/tr[1]/td\"))\n",
    "        print(no_cols)\n",
    "        \n",
    "        data=[]\n",
    "        for i in range(1,no_rows+1):\n",
    "            ro=[]\n",
    "            for j in range(1,no_cols+1):\n",
    "                print(driver.find_element_by_xpath('//table[@class=\"a-normal a-spacing-micro\"]/tbody/tr['+str(i)+']/td['+str(j)+']').text)\n",
    "                ro.append(driver.find_element_by_xpath('//table[@class=\"a-normal a-spacing-micro\"]/tbody/tr['+str(i)+']/td['+str(j)+']').text)\n",
    "            data.append(ro)\n",
    "        print(data)\n",
    " \n",
    "        \n",
    "    except:\n",
    "        data=\"\"\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_other_details(soup):\n",
    "    try:\n",
    "        item_list=[]\n",
    "        about_this_item=driver.find_elements_by_xpath('//*[@id=\"feature-bullets\"]/ul/li')\n",
    "        for item in about_this_item:\n",
    "            item_list.append(item.text)\n",
    "            print(item.text)\n",
    "        product_description=driver.find_element_by_xpath('//*[@id=\"productDescription\"]').text\n",
    "        item_list.append(product_description)\n",
    "        print(product_description.text)\n",
    "    except:\n",
    "            item_list=\"No description of the Product\"\n",
    "\n",
    "            \n",
    "    return item_list\n",
    "    \n",
    "\n",
    "def get_relatedproducts(soup):\n",
    "                count=0\n",
    "                related_products=[]\n",
    "                while count<=2:\n",
    "                    print(\"Inside while\")\n",
    "\n",
    "                    #time.sleep(3)\n",
    "                    try:\n",
    "\n",
    "                        print(\"In here\")\n",
    "                        #WebDriverWait(driver, 10).until(expected_conditions.element_to_be_clickable((By.XPATH, '//a[@class=\"a-button a-button-image a-carousel-button a-carousel-goto-nextpage\"]')))\n",
    "                        WebDriverWait(soup, 20).until(expected_conditions.visibility_of_element_located((By.XPATH, '//div[@class=\"a-carousel-col a-carousel-right\"]')))\n",
    "                        print(\"Next line\")\n",
    "                        nextpage=soup.find_element_by_xpath('//a[@class=\"a-button a-button-image a-carousel-button a-carousel-goto-nextpage\"]').get_attribute('href')\n",
    "                        soup.find_element_by_xpath('//a[@class=\"a-button a-button-image a-carousel-button a-carousel-goto-nextpage\"]').click()\n",
    "                        list=soup.find_elements_by_xpath('//div[@class=\"a-carousel-viewport\"]')\n",
    "                        print(list)\n",
    "                       \n",
    "                        for card in range(len(list)):\n",
    "                            related=soup.find_element_by_xpath('//li[@class=\"a-carousel-card\"]['+str(card+1)+']').text\n",
    "                            related_products.append(related)\n",
    "                            print(related)\n",
    "                        count+=1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        #break;\n",
    "                        print(\"Exception\",e)\n",
    "                        count+=1\n",
    "                        #condition=False\n",
    "                        print(\"In except\")\n",
    "                return related_products\n",
    "\n",
    "                print(\"After click()\")\n",
    "                \n",
    "def get_review_comments(driver):\n",
    "    try:\n",
    "        review_comment_list=[]\n",
    "        review_url=driver.find_element_by_xpath(\"//a[@data-hook='see-all-reviews-link-foot']\").click()\n",
    "        reviews_lists=driver.find_elements_by_xpath(\"//div[@data-hook='review']\")\n",
    "        print(reviews_lists)\n",
    "        for review in reviews_lists:\n",
    "            XPATH_RATING = './/i[@data-hook=\"review-star-rating\"]//span[@class=\"a-icon-alt\"]'\n",
    "            raw_review_rating = review.find_element_by_xpath(XPATH_RATING).get_attribute(\"innerHTML\")\n",
    "            XPATH_REVIEW_HEADER = './/a[@data-hook=\"review-title\"]//span'\n",
    "            XPATH_REVIEW_POSTED_DATE = './/span[@data-hook=\"review-date\"]'\n",
    "            XPATH_AUTHOR = './/span[contains(@class,\"profile-name\")]'\n",
    "            review_body=review.find_element_by_xpath(\".//span[@data-hook='review-body']\").text\n",
    "            raw_review_header = review.find_element_by_xpath(XPATH_REVIEW_HEADER).text\n",
    "            raw_review_posted_date = review.find_element_by_xpath(XPATH_REVIEW_POSTED_DATE).text\n",
    "            raw_review_author = review.find_element_by_xpath(XPATH_AUTHOR).text\n",
    "           \n",
    "            review_dict={}\n",
    "           \n",
    "            review_dict = {\n",
    "            \n",
    "            'review_text': review_body,\n",
    "            'review_posted_date': raw_review_posted_date,\n",
    "            'review_header': raw_review_header,\n",
    "            'review_rating': raw_review_rating,\n",
    "            'review_author': raw_review_author\n",
    "            }\n",
    "            review_comment_list.append(review_dict)   \n",
    "            print(review_comment_list)\n",
    "    except:\n",
    "        review_comment_list=\"No Reviews\"\n",
    "    return review_comment_list   \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "driver = create_webdriver()\n",
    "\n",
    "for page in range(1, 2):  # max of 20 pages\n",
    "            # load the next page\n",
    "            search_url = generate_url('t-shirt', page)\n",
    "            print(search_url)\n",
    "            driver.get(search_url)\n",
    "            driver.set_page_load_timeout(10)\n",
    "            print('TIMEOUT while waiting for page to load')\n",
    "\n",
    "           \n",
    "            links=driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "            link_list=[]\n",
    "            for link in links:\n",
    "                link_list.append(link.get_attribute(\"href\"))\n",
    "                #print(link_list)\n",
    "            \n",
    "            for link in link_list:\n",
    "                driver.get(link)\n",
    "\n",
    "                # Function calls to display all necessary product information\n",
    "                print(\"Product Title =\", get_title(driver))\n",
    "                print(\"Product Price =\", get_price(driver))\n",
    "                print(\"Product Rating =\", get_rating(driver))\n",
    "                print(\"Number of Product Reviews =\", get_review_count(driver))\n",
    "                print(\"Availability =\", get_availability(driver))\n",
    "                print(\"Product Details =\", get_productdetails(driver))\n",
    "                print()\n",
    "                print()\n",
    "                \n",
    "                print(\"Related Products:\",get_relatedproducts(driver))\n",
    "                \n",
    "                title=get_title(driver)\n",
    "                price=get_price(driver)\n",
    "                rating=get_rating(driver)\n",
    "                review_count=get_review_count(driver)\n",
    "                availability=get_availability(driver)\n",
    "                product_details=get_productdetails(driver)\n",
    "                other_product_details=get_other_details(driver)\n",
    "                related_product_details=get_relatedproducts(driver)\n",
    "                individual_review_count=get_individual_rating_counts(driver)\n",
    "                img_url=get_product_img(driver)\n",
    "                reviews_basedonfeature=get_reviews_based_onfeatures(driver)\n",
    "                print(reviews_basedonfeature)\n",
    "                review_counts=get_review_comments(driver)\n",
    "                \n",
    "                \n",
    "                final_data=[]\n",
    "                data_dict={}\n",
    "                data_dict[\"Title\"]=title\n",
    "                data_dict[\"Price\"]=price\n",
    "                data_dict[\"Rating\"]=rating\n",
    "                data_dict[\"Review_Count\"]=review_count\n",
    "                data_dict[\"Availability\"]=availability\n",
    "                data_dict[\"Details\"]=product_details\n",
    "                data_dict[\"Other Product Details\"]=other_product_details\n",
    "                data_dict[\"Related Product Details\"]=related_product_details\n",
    "                data_dict[\"Individual Rating Count\"]=individual_review_count\n",
    "                data_dict[\"Product IMG Link\"]=img_url\n",
    "                data_dict[\"Feature Based Review\"]=reviews_basedonfeature\n",
    "                data_dict[\"Review Comments\"]=review_counts\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                final_data.append(data_dict)\n",
    "                f=open(\"output.json\",\"a+\")\n",
    "                f.write(json.dumps(final_data,indent=2))\n",
    "                f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
